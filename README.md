<h1 align="center">MatrixVision</h1>

## Confusion Matrix

A confusion matrix is a performance measurement tool used in machine learning and statistics to evaluate the accuracy of a classification model. It is a table that allows visualization of the performance of an algorithm by comparing the predicted and actual classes of a dataset.

A confusion matrix typically has four cells, representing the following:

True Positives (TP): The number of data points correctly classified as belonging to the positive class.
True Negatives (TN): The number of data points correctly classified as belonging to the negative class.
False Positives (FP): The number of data points incorrectly classified as belonging to the positive class (actually negative).
False Negatives (FN): The number of data points incorrectly classified as belonging to the negative class (actually positive).

True Positives (TP): Instances that are correctly predicted as positive.
True Negatives (TN): Instances that are correctly predicted as negative.
False Positives (FP): Instances that are incorrectly predicted as positive (Type I error).
False Negatives (FN): Instances that are incorrectly predicted as negative (Type II error).

A confusion matrix provides insight into the performance of a classification model, including metrics such as accuracy, precision, recall, and F1-score. It is particularly useful for evaluating the performance of binary classification models but can be extended to multi-class classification problems as well.

### Scatter Plot

![image](https://github.com/BhavdeepSinghNijhawan/MatrixVision/assets/143419096/8885e86f-92f3-4bd7-97ef-e2988a189ee8)

### Confusion Matrix

![image](https://github.com/BhavdeepSinghNijhawan/MatrixVision/assets/143419096/84751a93-cb06-4156-b60d-b1c162392d6d)

## TOOL

- [MATLAB](https://matlab.mathworks.com/)

## CONTRIBUTOR

- [Bhavdeep Singh Nijhawan](https://www.linkedin.com/in/bhavdeep-singh-nijhawan-739634280)
